{'input_shape': (561, 1), 'n_blocks': 8, 'latent_dim': 50, 'encoder_latent_layer_type': 'variational', 'encoder_args': {'filters': [2, 4, 8, 16, 32, 64, 128, 256], 'kernel_size': [21, 18, 15, 13, 11, 8, 5, 3], 'padding': 'same', 'activation': 'selu', 'pooling': [1, 1, 1, 1, 1, 1, 1, 1]}}