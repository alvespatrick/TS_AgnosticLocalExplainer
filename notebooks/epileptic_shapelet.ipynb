{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = parentdir + \"/datasets/EpilepticSeizureRecognition/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"EpilepticSeizureRecognition\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(dataset_path + \"data.csv\", index_col = 0)\n",
    "y = np.array(X[\"y\"])\n",
    "y_all = np.ravel(y).astype(\"int\")\n",
    "for i in range(2,6):\n",
    "    y_all[y_all == i] = 2\n",
    "le = LabelEncoder()\n",
    "le.fit(y_all)\n",
    "y_all = le.transform(y_all)\n",
    "X_all = X.drop(\"y\", axis = 1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/francesco/anaconda3/envs/tesi/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/francesco/anaconda3/envs/tesi/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/francesco/anaconda3/envs/tesi/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/francesco/anaconda3/envs/tesi/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/francesco/anaconda3/envs/tesi/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/francesco/anaconda3/envs/tesi/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler # doctest: +NORMALIZE_WHITESPACE\n",
    "rus = RandomUnderSampler(random_state=random_state, )\n",
    "X_all, y_all = rus.fit_resample(X_all, y_all)\n",
    "\n",
    "X_all = X_all.reshape((X_all.shape[0], X_all.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X SHAPE:  (4600, 178, 1)\n",
      "y SHAPE:  (4600,)\n",
      "\n",
      "CLASSES BALANCE\n",
      "0 :  0.5\n",
      "1 :  0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"X SHAPE: \", X_all.shape)\n",
    "print(\"y SHAPE: \", y_all.shape)\n",
    "unique, counts = np.unique(y_all, return_counts=True)\n",
    "print(\"\\nCLASSES BALANCE\")\n",
    "for i, label in enumerate(unique):\n",
    "    print(label, \": \", round(counts[i]/sum(counts), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPES:\n",
      "BLACKBOX TRAINING SET:  (2060, 178, 1)\n",
      "BLACKBOX VALIDATION SET:  (516, 178, 1)\n",
      "BLACKBOX TEST SET:  (920, 178, 1)\n",
      "EXPLANATION TRAINING SET:  (706, 178, 1)\n",
      "EXPLANATION VALIDATION SET:  (177, 178, 1)\n",
      "EXPLANATION TEST SET:  (221, 178, 1)\n"
     ]
    }
   ],
   "source": [
    "# BLACKBOX TRAIN/TEST SETS SPLIT\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, \n",
    "                                                  test_size=0.2, stratify = y_all, random_state=random_state)\n",
    "\n",
    "# BLACKBOX/EXPLANATION SETS SPLIT\n",
    "X_train, X_exp, y_train, y_exp = train_test_split(X_train, y_train, \n",
    "                                                  test_size=0.3, stratify = y_train, random_state=random_state)\n",
    "\n",
    "# BLACKBOX TRAIN/VALIDATION SETS SPLIT\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
    "                                                  test_size=0.2, stratify = y_train, random_state=random_state)\n",
    "\n",
    "# EXPLANATION TRAIN/TEST SETS SPLIT\n",
    "X_exp_train, X_exp_test, y_exp_train, y_exp_test = train_test_split(X_exp, y_exp, \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    stratify = y_exp, \n",
    "                                                                    random_state=random_state)\n",
    "\n",
    "# EXPLANATION TRAIN/VALIDATION SETS SPLIT\n",
    "X_exp_train, X_exp_val, y_exp_train, y_exp_val = train_test_split(X_exp_train, y_exp_train, \n",
    "                                                                  test_size=0.2, \n",
    "                                                                  stratify = y_exp_train, \n",
    "                                                                  random_state=random_state)\n",
    "\n",
    "print(\"SHAPES:\")\n",
    "print(\"BLACKBOX TRAINING SET: \", X_train.shape)\n",
    "print(\"BLACKBOX VALIDATION SET: \", X_val.shape)\n",
    "print(\"BLACKBOX TEST SET: \", X_test.shape)\n",
    "print(\"EXPLANATION TRAINING SET: \", X_exp_train.shape)\n",
    "print(\"EXPLANATION VALIDATION SET: \", X_exp_val.shape)\n",
    "print(\"EXPLANATION TEST SET: \", X_exp_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS:  178\n",
      "N. LABELS:  2\n"
     ]
    }
   ],
   "source": [
    "n_timesteps, n_outputs, n_features = X_train.shape[1], len(np.unique(y_all)), 1 \n",
    "print(\"TIMESTEPS: \", n_timesteps)\n",
    "print(\"N. LABELS: \", n_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLACKBOX MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blackboxes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import blackboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import importlib\\nimportlib.reload(blackboxes)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import importlib\n",
    "importlib.reload(blackboxes)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/francesco/anaconda3/envs/tesi/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "blackbox = build_resnet(n_timesteps, n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "blackbox.load_weights(parentdir + \"/blackbox_checkpoints/EpilepticSeizureRecognition_blackbox_resnet_20200105_233014_best_weights_+0.99_.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = blackbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/francesco/anaconda3/envs/tesi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "blackbox = build_simple_CNN(n_timesteps, n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "blackbox.load_weights(parentdir + \"/blackbox_checkpoints/EpilepticSeizureRecognition_blackbox_simpleCNN_20200105_225722_best_weights_+0.98_.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplecnn = blackbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load, dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = load(parentdir + \"/blackbox_checkpoints/EpilepticSeizureRecognition_blackbox_knn_20200105_225631.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TENSORBOARD\n",
    "# tensorboard --logdir=/tmp/autoencoder\n",
    "# http://0.0.0.0:6006\n",
    "# lsof -i tcp:6006 | grep -v PID | awk '{print $2}' | xargs kill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import importlib\\nimportlib.reload(autoencoders)'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import autoencoders\n",
    "from autoencoders import *\n",
    "\"\"\"import importlib\n",
    "importlib.reload(autoencoders)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'input_shape': (178, 1), \n",
    "          'n_blocks': 8, \n",
    "          'latent_dim': 30, \n",
    "          'encoder_latent_layer_type': 'dense', \n",
    "          'encoder_args': {'filters': [2, 4, 8, 16, 32, 64, 128, 256], \n",
    "                           'kernel_size': [21, 18, 15, 13, 11, 8, 5, 3], \n",
    "                           'padding': 'same', \n",
    "                           'activation': 'elu', \n",
    "                           'pooling': [1, 1, 1, 1, 1, 1, 1, 1]}}\n",
    "\n",
    "aut = Autoencoder(**params, verbose = False)\n",
    "encoder, decoder, autoencoder = aut.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.load_weights(parentdir + \"/autoencoder_checkpoints/EpilepticSeizureRecognition_autoencoder_20200106_111007_best_weights_+14872.8621_.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLOBAL VS LOCAL SHAPELET TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 test set\n",
    "_, X_exp_test_50, _, y_exp_test_50 = train_test_split(X_exp_test, y_exp_test, \n",
    "                                                                  test_size=50, \n",
    "                                                                  stratify = y_exp_test, \n",
    "                                                                  random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francesco/anaconda3/envs/tesi/lib/python3.6/site-packages/deap/tools/_hypervolume/pyhv.py:33: ImportWarning: Falling back to the python version of hypervolume module. Expect this to be very slow.\n",
      "  \"module. Expect this to be very slow.\", ImportWarning)\n"
     ]
    }
   ],
   "source": [
    "import agnosticlocalexplainer\n",
    "from agnosticlocalexplainer import *\n",
    "\n",
    "from myutils import BlackboxPredictWrapper\n",
    "import time\n",
    "from agnosticglobalexplainer import AgnosticGlobalExplainer, save_shapelet_model, load_shapelet_model\n",
    "from joblib import dump\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, coverage_error\n",
    "from global_vs_local_surrogate import build_agnostic_local_explainers, print_report, massive_save_agnostic_local_explainers, massive_load_agnostic_local_explainers, get_all_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = autoencoder\n",
    "encoder = autoencoder.layers[1]\n",
    "decoder = autoencoder.layers[2]\n",
    "blackbox = resnet\n",
    "blackbox_input_dimensions = 3\n",
    "blackbox_predict = BlackboxPredictWrapper(blackbox,3)\n",
    "labels = [\"seizure\", \"no_seizure\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 50\n",
    "file_path = parentdir + \"/agnostic_explainers/\" + dataset_name + \"_\" + time.strftime(\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "if platform.system() == \"Windows\":\n",
    "    os.makedirs(file_path + \"/\")\n",
    "else: os.mkdir(file_path + \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "global_surrogate = AgnosticGlobalExplainer(random_state = random_state, \n",
    "                                           max_iter = max_iter, \n",
    "                                           distance_quantile_threshold = np.array(list(range(1,10)))/10,\n",
    "                                           labels = labels)\n",
    "global_surrogate.fit(X_exp_train[:,:,0], blackbox_predict.predict(X_exp_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "agnostic_explainers = build_agnostic_local_explainers(blackbox, \n",
    "                               encoder, \n",
    "                               decoder, \n",
    "                               autoencoder, \n",
    "                               X_exp_test_50, \n",
    "                               y_exp_test_50,\n",
    "                               blackbox_input_dimensions = blackbox_input_dimensions,\n",
    "                               labels = labels,\n",
    "                               size = 1000,\n",
    "                               neigh_type = \"geneticp\",\n",
    "                               ngen = 10,\n",
    "                              max_iter=max_iter,\n",
    "                              random_state = random_state,\n",
    "                              distance_quantile_threshold = np.array(list(range(1,10)))/10\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = get_all_predictions(agnostic_explainers, global_surrogate, blackbox_predict, X_exp_test_50, blackbox_predict.predict(X_exp_train), encoder, decoder)\n",
    "results_df.to_csv(file_path + \"/\" + \"results_df.csv\", sep = \";\", index = False)\n",
    "print_report(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "save_shapelet_model(global_surrogate, file_path + \"/\")\n",
    "massive_save_agnostic_local_explainers(agnostic_explainers, file_path, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "global_surrogate = load_shapelet_model(file_path + \"/\")\n",
    "agnostic_explainers = massive_load_agnostic_local_explainers(file_path, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "results_df_loaded = get_all_predictions(agnostic_explainers, global_surrogate, blackbox_predict, X_exp_test_50, blackbox_predict.predict(X_exp_train), encoder, decoder)\n",
    "print(sum(results_df_loaded.values != results_df.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 50\n",
      "2 / 50\n",
      "3 / 50\n",
      "4 / 50\n",
      "5 / 50\n",
      "6 / 50\n",
      "7 / 50\n",
      "8 / 50\n",
      "9 / 50\n",
      "10 / 50\n",
      "11 / 50\n",
      "12 / 50\n",
      "13 / 50\n",
      "14 / 50\n",
      "15 / 50\n",
      "16 / 50\n",
      "17 / 50\n",
      "18 / 50\n",
      "19 / 50\n",
      "20 / 50\n",
      "21 / 50\n",
      "22 / 50\n",
      "23 / 50\n",
      "24 / 50\n",
      "25 / 50\n",
      "26 / 50\n",
      "27 / 50\n",
      "28 / 50\n",
      "29 / 50\n",
      "30 / 50\n",
      "31 / 50\n",
      "32 / 50\n",
      "33 / 50\n",
      "34 / 50\n",
      "35 / 50\n",
      "36 / 50\n",
      "37 / 50\n",
      "38 / 50\n",
      "39 / 50\n",
      "40 / 50\n",
      "41 / 50\n",
      "42 / 50\n",
      "43 / 50\n",
      "44 / 50\n",
      "45 / 50\n",
      "46 / 50\n",
      "47 / 50\n",
      "48 / 50\n",
      "49 / 50\n",
      "50 / 50\n",
      "CPU times: user 17min 58s, sys: 20.2 s, total: 18min 19s\n",
      "Wall time: 18min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "global_surrogate = load_shapelet_model(parentdir + \"/agnostic_explainers/EpilepticSeizureRecognition_20200106_192815/\")\n",
    "agnostic_explainers = massive_load_agnostic_local_explainers(parentdir + \"/agnostic_explainers/EpilepticSeizureRecognition_20200106_192815/\", verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local fidelity:  1.0\n",
      "global fidelity:  0.96\n",
      "reconstruction fidelity:  0.98\n"
     ]
    }
   ],
   "source": [
    "results_df = get_all_predictions(agnostic_explainers, global_surrogate, blackbox_predict, X_exp_test_50, blackbox_predict.predict(X_exp_train), encoder, decoder)\n",
    "print_report(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SHAP\n",
    "\n",
    "from myutils import stabilities_df\n",
    "from shap_utils import shap_stability, shap_multi_stability\n",
    "\n",
    "save_path = parentdir + \"/stabilities/\" + dataset_name + \"_stability\" + \"_shap_\" + time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "params = {\"background\": \"linear\"}\n",
    "\n",
    "\n",
    "#### RESNET\n",
    "filename = save_path + \"_resnet\"\n",
    "stabilities = shap_multi_stability(X_exp_test_50, resnet, 3, point_by_point = False, **params)\n",
    "np.save(filename, stabilities)\n",
    "stabilities_df(stabilities, len(X_exp_test_50)).to_csv(filename + \".csv\", sep = \";\", index = True)\n",
    "\n",
    "\n",
    "#### CNN\n",
    "filename = save_path + \"_simplecnn\"\n",
    "stabilities = shap_multi_stability(X_exp_test_50, simplecnn, 3, point_by_point = False, **params)\n",
    "np.save(filename, stabilities)\n",
    "stabilities_df(stabilities, len(X_exp_test_50)).to_csv(filename + \".csv\", sep = \";\", index = True)\n",
    "\n",
    "\n",
    "#### KNN\n",
    "filename = save_path + \"_knn\"\n",
    "stabilities = shap_multi_stability(X_exp_test_50, knn, 2, point_by_point = False, **params)\n",
    "np.save(filename, stabilities)\n",
    "stabilities_df(stabilities, len(X_exp_test_50)).to_csv(filename + \".csv\", sep = \";\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from global_vs_local_surrogate import calculate_shapelet_stability\n",
    "\n",
    "n_neighbors = 30\n",
    "\n",
    "#### KNN\n",
    "file_path = parentdir + \"/agnostic_explainers/EpilepticSeizureRecognition_geneticp_knn_exc_20200117_091805/\"\n",
    "agnostic_explainers = massive_load_agnostic_local_explainers(file_path, verbose = True)\n",
    "\n",
    "save_path = parentdir + \"/stabilities/\" + dataset_name + \"_stability\" + \"_shapelets_\" + time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename = save_path + \"_knn\"\n",
    "\n",
    "stabilities = calculate_shapelet_stability(agnostic_explainers, X_exp_test_50, n_neighbors = n_neighbors)\n",
    "np.save(filename, stabilities)\n",
    "\n",
    "\n",
    "#### RESNET\n",
    "file_path = parentdir + \"/agnostic_explainers/EpilepticSeizureRecognition_geneticp_resnet_20200106_192815/\"\n",
    "agnostic_explainers = massive_load_agnostic_local_explainers(file_path, verbose = True)\n",
    "\n",
    "save_path = parentdir + \"/stabilities/\" + dataset_name + \"_stability\" + \"_shapelets_\" + time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename = save_path + \"_resnet\"\n",
    "stabilities = calculate_shapelet_stability(agnostic_explainers, X_exp_test_50, n_neighbors = n_neighbors)\n",
    "np.save(filename, stabilities)\n",
    "\n",
    "\n",
    "#### CNN\n",
    "file_path = parentdir + \"/agnostic_explainers/EpilepticSeizureRecognition_geneticp_simplecnn_20200109_180414/\"\n",
    "agnostic_explainers = massive_load_agnostic_local_explainers(file_path, verbose = True)\n",
    "\n",
    "save_path = parentdir + \"/stabilities/\" + dataset_name + \"_stability\" + \"_shapelets_\" + time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename = save_path + \"_simplecnn\"\n",
    "stabilities = calculate_shapelet_stability(agnostic_explainers, X_exp_test_50, n_neighbors = n_neighbors)\n",
    "np.save(filename, stabilities)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
