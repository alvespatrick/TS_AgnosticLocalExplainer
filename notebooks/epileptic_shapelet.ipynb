{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = parentdir + \"/datasets/EpilepticSeizureRecognition/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"EpilepticSeizureRecognition\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(dataset_path + \"data.csv\", index_col = 0)\n",
    "y = np.array(X[\"y\"])\n",
    "y_all = np.ravel(y).astype(\"int\")\n",
    "for i in range(2,6):\n",
    "    y_all[y_all == i] = 2\n",
    "le = LabelEncoder()\n",
    "le.fit(y_all)\n",
    "y_all = le.transform(y_all)\n",
    "X_all = X.drop(\"y\", axis = 1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler # doctest: +NORMALIZE_WHITESPACE\n",
    "rus = RandomUnderSampler(random_state=random_state, )\n",
    "X_all, y_all = rus.fit_resample(X_all, y_all)\n",
    "\n",
    "X_all = X_all.reshape((X_all.shape[0], X_all.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X SHAPE: \", X_all.shape)\n",
    "print(\"y SHAPE: \", y_all.shape)\n",
    "unique, counts = np.unique(y_all, return_counts=True)\n",
    "print(\"\\nCLASSES BALANCE\")\n",
    "for i, label in enumerate(unique):\n",
    "    print(label, \": \", round(counts[i]/sum(counts), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLACKBOX TRAIN/TEST SETS SPLIT\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, \n",
    "                                                  test_size=0.2, stratify = y_all, random_state=random_state)\n",
    "\n",
    "# BLACKBOX/EXPLANATION SETS SPLIT\n",
    "X_train, X_exp, y_train, y_exp = train_test_split(X_train, y_train, \n",
    "                                                  test_size=0.3, stratify = y_train, random_state=random_state)\n",
    "\n",
    "# BLACKBOX TRAIN/VALIDATION SETS SPLIT\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
    "                                                  test_size=0.2, stratify = y_train, random_state=random_state)\n",
    "\n",
    "# EXPLANATION TRAIN/TEST SETS SPLIT\n",
    "X_exp_train, X_exp_test, y_exp_train, y_exp_test = train_test_split(X_exp, y_exp, \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    stratify = y_exp, \n",
    "                                                                    random_state=random_state)\n",
    "\n",
    "# EXPLANATION TRAIN/VALIDATION SETS SPLIT\n",
    "X_exp_train, X_exp_val, y_exp_train, y_exp_val = train_test_split(X_exp_train, y_exp_train, \n",
    "                                                                  test_size=0.2, \n",
    "                                                                  stratify = y_exp_train, \n",
    "                                                                  random_state=random_state)\n",
    "\n",
    "print(\"SHAPES:\")\n",
    "print(\"BLACKBOX TRAINING SET: \", X_train.shape)\n",
    "print(\"BLACKBOX VALIDATION SET: \", X_val.shape)\n",
    "print(\"BLACKBOX TEST SET: \", X_test.shape)\n",
    "print(\"EXPLANATION TRAINING SET: \", X_exp_train.shape)\n",
    "print(\"EXPLANATION VALIDATION SET: \", X_exp_val.shape)\n",
    "print(\"EXPLANATION TEST SET: \", X_exp_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps, n_outputs, n_features = X_train.shape[1], len(np.unique(y_all)), 1 \n",
    "print(\"TIMESTEPS: \", n_timesteps)\n",
    "print(\"N. LABELS: \", n_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLACKBOX MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blackboxes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import blackboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import importlib\n",
    "importlib.reload(blackboxes)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blackbox = build_resnet(n_timesteps, n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blackbox.load_weights(parentdir + \"/blackbox_checkpoints/EpilepticSeizureRecognition_blackbox_resnet_20200105_233014_best_weights_+0.99_.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = blackbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blackbox = build_simple_CNN(n_timesteps, n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blackbox.load_weights(parentdir + \"/blackbox_checkpoints/EpilepticSeizureRecognition_blackbox_simpleCNN_20200105_225722_best_weights_+0.98_.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplecnn = blackbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load, dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = load(parentdir + \"/blackbox_checkpoints/EpilepticSeizureRecognition_blackbox_knn_20200105_225631.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TENSORBOARD\n",
    "# tensorboard --logdir=/tmp/autoencoder\n",
    "# http://0.0.0.0:6006\n",
    "# lsof -i tcp:6006 | grep -v PID | awk '{print $2}' | xargs kill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autoencoders\n",
    "from autoencoders import *\n",
    "\"\"\"import importlib\n",
    "importlib.reload(autoencoders)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'input_shape': (178, 1), \n",
    "          'n_blocks': 8, \n",
    "          'latent_dim': 30, \n",
    "          'encoder_latent_layer_type': 'dense', \n",
    "          'encoder_args': {'filters': [2, 4, 8, 16, 32, 64, 128, 256], \n",
    "                           'kernel_size': [21, 18, 15, 13, 11, 8, 5, 3], \n",
    "                           'padding': 'same', \n",
    "                           'activation': 'elu', \n",
    "                           'pooling': [1, 1, 1, 1, 1, 1, 1, 1]}}\n",
    "\n",
    "aut = Autoencoder(**params, verbose = False)\n",
    "encoder, decoder, autoencoder = aut.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.load_weights(parentdir + \"/autoencoder_checkpoints/EpilepticSeizureRecognition_autoencoder_20200106_111007_best_weights_+14872.8621_.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLOBAL VS LOCAL SHAPELET TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 test set\n",
    "_, X_exp_test_50, _, y_exp_test_50 = train_test_split(X_exp_test, y_exp_test, \n",
    "                                                                  test_size=50, \n",
    "                                                                  stratify = y_exp_test, \n",
    "                                                                  random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import agnosticlocalexplainer\n",
    "from agnosticlocalexplainer import *\n",
    "\n",
    "from myutils import BlackboxPredictWrapper\n",
    "import time\n",
    "from agnosticglobalexplainer import AgnosticGlobalExplainer, save_shapelet_model, load_shapelet_model\n",
    "from joblib import dump\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, coverage_error\n",
    "from global_vs_local_surrogate import build_agnostic_local_explainers, print_report, massive_save_agnostic_local_explainers, massive_load_agnostic_local_explainers, get_all_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = autoencoder\n",
    "encoder = autoencoder.layers[1]\n",
    "decoder = autoencoder.layers[2]\n",
    "blackbox = resnet\n",
    "blackbox_input_dimensions = 3\n",
    "labels = [\"seizure\", \"no_seizure\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 50\n",
    "file_path = parentdir + \"/agnostic_explainers/\" + dataset_name + \"_\" + time.strftime(\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "if platform.system() == \"Windows\":\n",
    "    os.makedirs(file_path + \"/\")\n",
    "else: os.mkdir(file_path + \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "global_surrogate = AgnosticGlobalExplainer(random_state = random_state, \n",
    "                                           max_iter = max_iter, \n",
    "                                           distance_quantile_threshold = np.array(list(range(1,10)))/10,\n",
    "                                           labels = labels)\n",
    "global_surrogate.fit(X_exp_train[:,:,0], blackbox_predict.predict(X_exp_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "agnostic_explainers = build_agnostic_local_explainers(blackbox, \n",
    "                               encoder, \n",
    "                               decoder, \n",
    "                               autoencoder, \n",
    "                               X_exp_test_50, \n",
    "                               y_exp_test_50,\n",
    "                               blackbox_input_dimensions = blackbox_input_dimensions,\n",
    "                               labels = labels,\n",
    "                               size = 1000,\n",
    "                               neigh_type = \"geneticp\",\n",
    "                               ngen = 10,\n",
    "                              max_iter=max_iter,\n",
    "                              random_state = random_state,\n",
    "                              distance_quantile_threshold = np.array(list(range(1,10)))/10\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = get_all_predictions(agnostic_explainers, global_surrogate, blackbox_predict, X_exp_test_50, blackbox_predict.predict(X_exp_train), encoder, decoder)\n",
    "results_df.to_csv(file_path + \"/\" + \"results_df.csv\", sep = \";\", index = False)\n",
    "print_report(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "save_shapelet_model(global_surrogate, file_path + \"/\")\n",
    "massive_save_agnostic_local_explainers(agnostic_explainers, file_path, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "global_surrogate = load_shapelet_model(file_path + \"/\")\n",
    "agnostic_explainers = massive_load_agnostic_local_explainers(file_path, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "results_df_loaded = get_all_predictions(agnostic_explainers, global_surrogate, blackbox_predict, X_exp_test_50, blackbox_predict.predict(X_exp_train), encoder, decoder)\n",
    "print(sum(results_df_loaded.values != results_df.values))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
