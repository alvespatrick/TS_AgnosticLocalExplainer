{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pyts.datasets import make_cylinder_bell_funnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"cbf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all, y_all = make_cylinder_bell_funnel(n_samples = 600, random_state = random_state)\n",
    "X_all = X_all.reshape((X_all.shape[0], X_all.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X SHAPE:  (600, 128, 1)\n",
      "y SHAPE:  (600,)\n",
      "\n",
      "CLASSES BALANCE\n",
      "0 :  0.33\n",
      "1 :  0.33\n",
      "2 :  0.33\n"
     ]
    }
   ],
   "source": [
    "print(\"X SHAPE: \", X_all.shape)\n",
    "print(\"y SHAPE: \", y_all.shape)\n",
    "unique, counts = np.unique(y_all, return_counts=True)\n",
    "print(\"\\nCLASSES BALANCE\")\n",
    "for i, label in enumerate(unique):\n",
    "    print(label, \": \", round(counts[i]/sum(counts), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPES:\n",
      "BLACKBOX TRAINING SET:  (268, 128, 1)\n",
      "BLACKBOX VALIDATION SET:  (68, 128, 1)\n",
      "BLACKBOX TEST SET:  (84, 128, 1)\n",
      "EXPLANATION TRAINING SET:  (115, 128, 1)\n",
      "EXPLANATION VALIDATION SET:  (29, 128, 1)\n",
      "EXPLANATION TEST SET:  (36, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "# BLACKBOX/EXPLANATION SETS SPLIT\n",
    "X_train, X_exp, y_train, y_exp = train_test_split(X_all, y_all, \n",
    "                                                  test_size=0.3, stratify = y_all, random_state=random_state)\n",
    "\n",
    "# BLACKBOX TRAIN/TEST SETS SPLIT\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, \n",
    "                                                  test_size=0.2, stratify = y_train, random_state=random_state)\n",
    "\n",
    "# BLACKBOX TRAIN/VALIDATION SETS SPLIT\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
    "                                                  test_size=0.2, stratify = y_train, random_state=random_state)\n",
    "\n",
    "# EXPLANATION TRAIN/TEST SETS SPLIT\n",
    "X_exp_train, X_exp_test, y_exp_train, y_exp_test = train_test_split(X_exp, y_exp, \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    stratify = y_exp, \n",
    "                                                                    random_state=random_state)\n",
    "\n",
    "# EXPLANATION TRAIN/VALIDATION SETS SPLIT\n",
    "X_exp_train, X_exp_val, y_exp_train, y_exp_val = train_test_split(X_exp_train, y_exp_train, \n",
    "                                                                  test_size=0.2, \n",
    "                                                                  stratify = y_exp_train, \n",
    "                                                                  random_state=random_state)\n",
    "\n",
    "print(\"SHAPES:\")\n",
    "print(\"BLACKBOX TRAINING SET: \", X_train.shape)\n",
    "print(\"BLACKBOX VALIDATION SET: \", X_val.shape)\n",
    "print(\"BLACKBOX TEST SET: \", X_test.shape)\n",
    "print(\"EXPLANATION TRAINING SET: \", X_exp_train.shape)\n",
    "print(\"EXPLANATION VALIDATION SET: \", X_exp_val.shape)\n",
    "print(\"EXPLANATION TEST SET: \", X_exp_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEPS:  128\n",
      "N. LABELS:  3\n"
     ]
    }
   ],
   "source": [
    "n_timesteps, n_outputs, n_features = X_train.shape[1], len(np.unique(y_all)), 1 \n",
    "print(\"TIMESTEPS: \", n_timesteps)\n",
    "print(\"N. LABELS: \", n_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLACKBOX MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from joblib import load\n",
    "import keras\n",
    "\"\"\"import importlib\n",
    "importlib.reload(blackboxes)\"\"\"\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "import blackboxes\n",
    "from blackboxes import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/francesco/anaconda3/envs/tesi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/francesco/anaconda3/envs/tesi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/francesco/anaconda3/envs/tesi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/francesco/anaconda3/envs/tesi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/francesco/anaconda3/envs/tesi/lib/python3.6/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/francesco/anaconda3/envs/tesi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/francesco/anaconda3/envs/tesi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/francesco/anaconda3/envs/tesi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/francesco/anaconda3/envs/tesi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/francesco/anaconda3/envs/tesi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/francesco/anaconda3/envs/tesi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/francesco/anaconda3/envs/tesi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "blackbox = build_resnet(n_timesteps, n_outputs)\n",
    "blackbox.load_weights(parentdir + \"/blackbox_checkpoints/cbf_blackbox_resnet_20191106_145242_best_weights_+1.00_.hdf5\")\n",
    "resnet = blackbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/francesco/anaconda3/envs/tesi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "blackbox = build_simple_CNN(n_timesteps, n_outputs)\n",
    "blackbox.load_weights(parentdir + \"/blackbox_checkpoints/cbf_blackbox_simpleCNN_20191106_145515_best_weights_+1.00_.hdf5\")\n",
    "simplecnn = blackbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = load(parentdir + \"/blackbox_checkpoints/cbf_blackbox_knn_20191106_145654.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import importlib\n",
    "importlib.reload(autoencoders)\"\"\"\n",
    "import autoencoders\n",
    "from autoencoders import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STANDARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/francesco/anaconda3/envs/tesi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/francesco/anaconda3/envs/tesi/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4409: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\"input_shape\": (n_timesteps,1),\n",
    "          \"n_blocks\": 8, \n",
    "          \"latent_dim\": 2,\n",
    "          \"encoder_latent_layer_type\": \"dense\",\n",
    "          \"encoder_args\": {\"filters\":[2,4,8,16,32,64,128,256], \n",
    "                            \"kernel_size\":[21,18,15,13,11,8,5,3], \n",
    "                            \"padding\":\"same\", \n",
    "                            \"activation\":\"elu\", \n",
    "                            \"pooling\":[1,1,1,1,1,1,1,1]}\n",
    "         }\n",
    "\n",
    "aut = Autoencoder(verbose = False, **params)\n",
    "encoder, decoder, autoencoder = aut.build()\n",
    "autoencoder.load_weights(\"./autoencoder_checkpoints/cbf_autoencoder_20191106_144056_best_weights_+1.0504_.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLOBAL VS LOCAL SHAPELET TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francesco/anaconda3/envs/tesi/lib/python3.6/site-packages/deap/tools/_hypervolume/pyhv.py:33: ImportWarning: Falling back to the python version of hypervolume module. Expect this to be very slow.\n",
      "  \"module. Expect this to be very slow.\", ImportWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'agnosticlocalexplainer' from '/Users/francesco/github/TS_AgnosticLocalExplainer/agnosticlocalexplainer.py'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import agnosticlocalexplainer\n",
    "from agnosticlocalexplainer import *\n",
    "import importlib\n",
    "importlib.reload(agnosticlocalexplainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myutils import BlackboxPredictWrapper\n",
    "import time\n",
    "from agnosticglobalexplainer import AgnosticGlobalExplainer\n",
    "from joblib import dump\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, coverage_error\n",
    "from global_vs_local_surrogate import shapelet_local_explain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = autoencoder.layers[1]\n",
    "decoder = autoencoder.layers[2]\n",
    "blackbox = resnet\n",
    "blackbox_input_dimensions = 3\n",
    "blackbox_predict = BlackboxPredictWrapper(blackbox, 3)\n",
    "labels = [\"cylinder\", \"bell\", \"funnel\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 50\n",
    "file_path = parentdir + \"/agnostic_explainers/\" + dataset_name + \"_\" + time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "os.mkdir(file_path + \"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_surrogate = AgnosticGlobalExplainer(random_state = random_state, max_iter = max_iter, labels = labels)\n",
    "global_surrogate.fit(X_exp_train[:,:,0], blackbox_predict.predict(X_exp_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed:    3.0s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "agnostic_explainers = build_agnostic_local_explainers(blackbox, \n",
    "                               encoder, \n",
    "                               decoder, \n",
    "                               autoencoder, \n",
    "                               X_exp_test, \n",
    "                               y_exp_test,\n",
    "                               blackbox_input_dimensions = blackbox_input_dimensions,\n",
    "                               labels = labels,\n",
    "                               size = 1000,\n",
    "                               neigh_type = \"geneticp\",\n",
    "                               ngen = 10,\n",
    "                              max_iter=max_iter,\n",
    "                              random_state = random_state\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = get_all_predictions(agnostic_explainers, global_surrogate, blackbox_predict, X_exp_test, blackbox_predict.predict(X_exp_train))\n",
    "results_df.to_csv(file_path + \"/\" + \"results_df.csv\", sep = \";\", index = False)\n",
    "print_report(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "save_shapelet_model(global_surrogate, file_path + \"/\")\n",
    "massive_save_agnostic_local_explainers(agnostic_explainers, file_path, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "global_surrogate = load_shapelet_model(file_path + \"/\")\n",
    "agnostic_explainers = massive_load_agnostic_local_explainers(file_path, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "results_df_loaded = get_all_predictions(agnostic_explainers, global_surrogate, blackbox_predict)\n",
    "print(sum(results_df_loaded.values != results_df.values))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
